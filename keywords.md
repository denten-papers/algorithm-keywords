---
title: "Preliminary Remarks on Algorithmic Governance"
author: "Dennis Yi Tenen"
mainfont: "fbb"
fontsize: 12pt
classoption: none
header-includes:
- \usepackage{titlesec}
- \newcommand{\sectionbreak}{\clearpage}
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \rhead{\today\hspace{0.5em}|\hspace{0.5em}draft copy\hspace{0.5em}|\hspace{0.5em}do not circulate}
- \lhead{}
---

I would like consider the concept of an algorithm apart from its rich history
in mathematics, which stems back to the work the great ninth-century Persian
mathematician Al-Khwarizmi, the "one from Kwarizm" (modern Khiva), the eponym
also at the root of the Spanish *guarismo*, meaning decimal number.[^1]
According to Donald Knuth, one of modern day's most significant scholars and
architects of algorithms, the word should simply mean a "well defined process"
which includes the "structuring of data" as well as the "sequence of
operations being performed." He writes also about the "miscellaneous methods
for the solution of particular problems analogous to individual theorems in
mathematics."[^1]

The alternative history of algorithms I propose here points to a particular
kind of an inscription---a script---a type of an imperative utterance and
thereby more broadly a species of *agency displaced* in time and place, a
condition particular to all imperatives, be they machine code or legal codex.
Viewed from the vantage point of political theory, the social problems of the
sort Frank Pasquale identifies in his *The Black Box Society: The Secret
Algorithms That Control Money and Information*---the opaque nature of
algorithmic control regimes like search engines, spam filters, and high-speed
financial trading bots---can be perceived as part of a long-standing debate
about the nature of political formation, particularly as it relates to issues
of personal agency, culpability, and consent.[^3]

Consider the following simple thought experiment. You are wont to eat toast
for breakfast. To make the toast you usually place a slice of bread into a
machine especially for this purpose, a toaster. The machine takes several
minutes to complete its task. Imagine also being once interrupted shortly
after the start of the toasting process. An urgent phone call takes you out of
the kitchen. What are we to make of the machine absent the source of its
volitional impetus? Does it "make" the toast on its own? Does it "want" to
make it? Were an accident to happen, a fire or an electrical malfunction, who
would be responsible, the machine, its manufacturer, or its absent master?
Whatever intuitions the reader may have about such simple machines, they
should, in aggregate, also guide our thinking about inhabiting complex
political systems, which comprise an intricate assemblage of biological,
technical, and symbolic structures.

Similar questions (about agency and consensus) present themselves where the
volitional agent delegates responsibility to another human, instead of a
machine. In our hypothetical toast-making example, we can imagine leaving a
set of detailed instructions to a family member, who would again follow them
"on your behalf" at a later time. Words like "delegate" and "on your behalf"
mark what I have been calling here the problem of displaced agency. In both
cases, the action is completed in the absence of the volitional source. I was
the one *wanting* toast yet my relative was the one *making* it. Our humble
toaster or a recipe for toast---do X, then Y, then Z---similarly contains a
disembodied spark of some such originating wants, appetites, or desires. The
algorithm allows one to universalize and to delay the performance of an
action. It involves formalizing and formulating the imperative into a sequence
of symbolic steps, which can be enacted by mechanisms other than those of my
own body, which incidentally does not need such explicitly formulaic
procedures. The algorithm makes the action repeatable, independent of its
original medium and exact mechanism of execution. I don't need to account for
the exact procedures of how to make toast to myself. But in designing a
toaster, the engineer breaks the desired effect into discrete reproducible
steps, which in effect comprise the algorithm of generalized toast making.

Without some such recipe, script, or heuristic, the will to act and the action
would have to happen contiguously. The will to act and the performance of an
action connect causally, in a chain of what Ludwig Wittgenstein has described
as a kind of a rigid mechanism, which he also equates with an "obedient
man".[^4][^5] The subject and the object of action occupy the same contiguous
time and space: you do something and see the effect of the action immediately.
The algorithm lengthens the causal chain between subject and object,
disconnecting cause from immediate affect. Instead of making the toast
immediately, one can set a timer, leave the room, and have the toast made
automatically at some specified time in the future. One can also send detailed
instructions to have something done elsewhere, by phone or by mail. The effect
is the same: the generalized instructions lengthen the chain between will and
execution. They provide also the instructions for the "rigid mechanism" which
would connect the outcomes to their execution.

This delayed nature of algorithm execution hampers our ability to reconstruct
the flows of agency. Colloquially, we minimize this difficulty through
volitional metaphors, using language usually reserved for other minds, in what
Katherine Hayles has called the "cognitive nonconcious."[^3] In this way,
toasters routinely "refuse" to work, countries "decide" to invade other
countries, devices gain "smarts," and corporations "assert" their right to
"speak." When habituated, the language of the cognitive nonconcious obscures
the analogical nature of the linguistic convenience. What is meant by
"refusing," "deciding," "intelligence," "asserting," and "speaking" cannot be
equated to the conventional meaning of these words, usually reserved for
agents both cognitive and concious outright.

It is all the more tempting to ascribe a kind of an inner life, a
phenomenology, to novel artifacts of displaced volition: object oriented
phenomenology. In reality, such inner states are at best a convenient fiction
and at worst, a fetish or a delusion created to obscure the flows of
governance and culpability. To put it bluntly: country X has "decided" to do Y
often translates into "three white dudes discussed it briefly in a room behind
closed doors." Whatever the reader's politics, one must see the obvious
political implications of inhabiting an unexamined metaphor. Edsger W.
Dijkstra, another foundational figure in computer science, wrote about the
need to "liberate ourselves" from the habit of approaching the topic in terms
of anthropomorphic analogies, by which algorithms---computer programs---"try
to do things," "want to do things," "believe things to be true," "know
things," and so on. The metaphor obscures the exacting formal nature of
machine logic. Even more problematically for us, the anthropomorphising of
algorithms obscures causal chains that should instead lead to actual actors
engaged in the political struggle for power, capital, and ultimately control
(which is more or less the thesis of Pasquale's book, minus the metaphor parts
which are mine).

In this sense, the seemingly exceptional problem of algorithmic
accountability---to what extent do algorithms produce market volatility, or
are produced by it? for example---is related to the long-standing problem of
continuing consent, as expressed in the political thought of Hobbes, Locke,
and Rousseau among others. Like algorithms, laws continue to govern based on
consensual structures that persist far beyond the originating accord.
Classical liberal thought imagines democratic governance to arise out of an
initial founding moment, through explicit agreement among free individuals.
But for most people, law and regulations constitute a part of a received
technological a priori. Existing laws govern among members who have never had
a chance to consent to them. One is given the opportunity to consent tacitly
instead, through the use of shared resources for example, although this does
not afford much possibility for change or deliberation. The "system" proceeds
seemingly by the logic of its own, neither fully understood nor consented to
by its constituents. The net effect is broadly disenfranchising. The
complexity of received institutional heritage---the Hobbsean
leviathan---results in what Langdon Winner has called "technics
out-of-control" and alternatively the illusion of "autonomous technology."[^7]
To these points he cites Max Horkheimer, who wrote that:

> as material productions and social organization grow more complicated and
> reified, recognition of means as such becomes increasingly difficult, since
> they assume the appearance of autonomous agents.[^8]

The pathway between political theory and theory of algorithms, of the kind I
can only gesture towards in this short piece, suggests also the reciprocal
movement between the practices of software engineering and political science.
A body of work is beginning to emerge on the topic of *algorithmic
governance.[^9] To view legislature as a kind of "software" for the hardware
of institutions opens the possibility of adopting software tools and technics
designed to mitigate some of the complexities of code maintenance at scale.
Among such approaches:

- Peer production, a decentralized way of coordinating labor among thousands
  of contributors.
- Version control, a kind of a "track changes" system for maintaining large
  codebases.
- Fuzzing, the input of random and often invalid data to "stress test" the
  system for robustness against unforeseen states of exception.
- Program mutation, the practice of modifying the code in small increments to
  improve software testing protocols.

The notion of algorithmic governance points to several exciting and as yet
unexplored avenues for research, both applied and theoretical. The algorithm
emerges as an artifact of displaced volition, one among many such artifacts
that deserve careful elaboration and further critical attention.

[^1]: Knuth, Donald E. “Algorithms in Modern Mathematics and Computer Science.” In *Proceedings on Algorithms in Modern Mathematics and Computer Science*, 82–99. London, UK: Springer-Verlag, 1981.

[^3]: Pasquale, Frank. *The Black Box Society: The Secret Algorithms That Control Money and Information*, 2015.

[^4]: Hayles, N. Katherine. “Cognition Everywhere: The Rise of the Cognitive Nonconscious and the Costs of Consciousness.” *New Literary History New Literary History* 45, no. 2 (2014): 199–220.

[^5]: See Wittgenstein, Ludwig, R. G Bosanquet, and Cora Diamond.  *Wittgenstein's Lectures on the Foundations of Mathematics, Cambridge, 1939: From the Notes of R.G. Bosanquet, Norman Malcolm, Rush Rhees, and Yorick Smythies*. Ithaca, N.Y.: Cornell University Press, 1976: 282 and Wittgenstein, Ludwig, and Rush Rhees. *Philosophical grammar*. Berkeley: University of California Press, 1974: 60-70.

[^6]: Edsger, Dijkstra. “The Fruits of Misunderstanding.” Netherlands, May 19, 1983.

[^7]: Winner, Langdon. *Autonomous Technology: Technics-out-of-Control as a Theme in Political Thought*. Cambridge, Mass.: MIT Press, 1978: 279-305.

[^8]: Horkheimer, Max. *Eclipse of Reason*. New York: Continuum, 1974. Cited in Winner, Langdon. *Autonomous Technology: Technics-out-of-Control as a Theme in Political Thought*. Cambridge, Mass.: MIT Press, 1978: 305

[^9]: See for example Pitt, J., and A. Diaconescu. “Structure and Governance of Communities for the Digital Society.” In 2015 IEEE International Conference on Autonomic Computing (ICAC), 279–84, 2015.
