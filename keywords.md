---
title: "Preliminary Remarks on Algorithmic Governance"
author: "Dennis Yi Tenen"
mainfont: "fbb"
fontsize: 12pt
documentclass: article
classoption: none
header-includes:
- \usepackage{titlesec}
- \newcommand{\sectionbreak}{\clearpage}
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \rhead{\today\hspace{0.5em}|\hspace{0.5em}draft copy\hspace{0.5em}|\hspace{0.5em}do not circulate}
- \lhead{}
---

I would like consider the concept of an algorithm apart from its rich history
in mathematics, which stems back to the work the great ninth-century Persian
mathematician Al-Khwarizmi, the "one from Kwarizm" (modern Khiva), the eponym
also at the root of the Spanish *guarismo*, meaning decimal number.[^1]
According to Donald Knuth, one of modern day's most significant scholars and
architects of algorithm, the word should simply mean a "well defined process"
which includes the "structuring of data" as well as the "sequence of
operations being performed. He writes also about the "miscellaneous methods
for the solution of particular problems analogous to individual theorems in
mathematics."[^2]

The alternative history of algorithms I propose here points to a particular
kind of an inscription---a script---a type of an imperative utterance and
thereby more broadly a species of *agency displaced* in time and place
particular to all imperatives, be they machine code or legal codex. Viewed
from the vantage point of political theory, the social problems of the sort
Frank Pasquale identifies in his *The Black Box Society: The Secret Algorithms
That Control Money and Information*---the opaque nature of algorithmic control
regimes like search engines, spam filters, and high-speed financial trading
bots---can be perceived as part of a long-standing debate about the nature of
political formation, particularly as it relates to issues of personal agency,
culpability, and consent.[^3]

Consider the following simple thought experiment. You are wont to eat toast
for breakfast. To make the toast you usually place a slice of bread into a
machine especially for this purpose, a toaster. The machine takes several
minutes to complete its task. Imagine also being once interrupted shortly
after the start of the toasting process. An urgent phone call takes you out of
the kitchen. What are we to make of the machine absent the source of its
volitional impetus? Does it "make" the toast on its own? Does it "want" to
make it? Were an accident to happen, a fire or an electrical malfunction, who
would be responsible, the machine, its manufacturer, or its absent master?
Whatever intuitions the reader may have about such simple machines, they
should, in aggregate, guide our thinking about inhabiting complex political
systems, which comprise an intricate assemblage of biological, technical, and
symbolic structures.

Similar questions (about agency and consensus) present themselves where the
volitional agent delegates responsibility to another human, instead of a
machine. In our hypothetical toast-making example, we can imagine leaving a
set of detailed instructions to a family member, who would follow them again
"on your behalf" at a later time. Words like "delegate" and "on your behalf"
mark what I have been calling here the problem of displaced agency. In both
cases, the action is completed in the absence of the volitional source. I was
the one who wanted toast but my friend made it for me. Our humble toaster or a
recipe for toast contains---do X, then Y, then Z---contains a disembodied
spark of its originating wants, appetites, desires. In the case of an
algorithm, we delay the performance of the action by formalizing and
formulating the imperative into a sequence of symbolic steps. Without the
recipe or a script, the will to act and the action would have to happen
contiguously.

Under normal circumstances, the will to act and the performance of an action
connect causally, in a chain of what Ludwig Wittgenstein has described as a
kind of a rigid mechanism, which he also equates with an "obedient man".[^5,4]
The subject and the object of action occupy the same contiguous time and
space: you do something and see the effect of the action immediately. The
algorithm lengthens the causal chain between subject and object, making the
flows of agency difficult to reconstruct precisely. Colloquially, we minimize
this difficulty through volitional metaphors, using language usually reserved
for other minds, in what Katherine Hayles has called the "cognitive
nonconcious."[^2] In this way, toasters routinely "refuse" to work, countries
"decide" to invade other countries, devices gain "smarts," and corporations
can hold the right to "speak." When habituated, the language of the "cognitive
nonconcious" obscures the analogical nature of the linguistic convenience.
What is meant by "refusing," "deciding," "intelligence," and "speaking" cannot
be equated to the conventional meaning of these words, usually reserved for
agents both cognitive and concious outright.

It is all the more tempting to ascribe a kind of an inner life, a
phenomenology, to novel artifacts of displaced volition: object oriented
phenomenology. In reality, such inner states are at best a convenient fiction
and at worst, a fetish or an outright delusion designed to obscure the flows
of governance and culpability. To be blunt: country X has "decided" too often
translates to "three white dudes discussed it briefly in a room behind closed
doors." Whatever the reader's politics, one must see the obvious political
implications of leaving the metaphor as is. Edsger W. Dijkstra, another
foundational figure in computer science, wrote about the need to "liberate
ourselves" from the habit of approaching the topic in terms of anthropomorphic
analogies, by which algorithms---computer programs---"try to do things," "want
to do things," "believe things to be true," "know things," and so on. The
metaphor obscures the formal nature of machine logic. Even more
problematically for us, the anthropomorphising of algorithm obscures causal
chains that should instead lead to actual actors engaged in dynamics of power,
capital, and ultimately control (which is more or less the thesis of
Pasquale's book, minus the metaphor parts which are mine).

In this sense, the seemingly exceptional problem of algorithmic
accountability---to what extent do algorithms produce market volatility, or
are produced by it?---is related to the long-standing problem of continuing
consent as expressed in the political thought of Hobbes, Locke, and Rousseau.
Like algorithms, laws continue to govern based on consensual structures that
persist far beyond the originating accord. Classical liberal thought imagines
democratic governance to arise out of an initial founding moment, through
explicit agreement among free individuals. But for most people, law and
regulations constitute a part of technological a priori: they continue to
govern among members who have not participated in the political process of
consensus formation. And although we consent tacitly, through the use of
shared resources for example, we are thereby disenfranchised in the process.
The complexity of the Hobbsean leviathan results in what Langdon Winner has
called "technics out of control." To these conclusions he cites Max
Horkheimer, writes that:

> as material productions and social organization grow more complicated and
reified, recognition of means as such becomes increasingly difficult, since
they assume the appearance of autonomous agents.[^7]

The pathway between political theory and theory of algorithms, of the kind I
can only gesture towards in this short piece, suggests also the reciprocal
movement between the practices of software engineering and political science.
A body of work is beginning to emerge on the topic of *algorithmic
governance.[^10] To view legislature as a kind of "software" for the hardware
of institutions opens the possibility of adopting software tools and technics
designed to mitigate some of the complexities of code development at scale.
Among such approaches:

- Peer production, ways of coordinating labor among thousands of contributors.
- Version control, a kind of "track changes" system for maintaining large
  codebases.
- Fuzzing, the input of random and often invalid data to "stress test" the
  system for robustness against unforeseen states of exception.
- Program mutation, the practice of modifying the code in small increments to
improve software testing protocols.

The notion of algorithmic governance points to exciting and as yet unexplored
avenues for research, both applied and theoretical. The algorithm emerges as
an artifact of displaced volition, one among many such documents that deserve
further critical attention.

[^1]: Knuth, Donald E. “Algorithms in Modern Mathematics and Computer
Science.” In *Proceedings on Algorithms in Modern Mathematics and Computer
Science*, 82–99. London, UK: Springer-Verlag, 1981.

[^2]: Knuth, Donald E. “Algorithms in Modern Mathematics and Computer
Science.” In *Proceedings on Algorithms in Modern Mathematics and Computer
Science*, 82. London, UK: Springer-Verlag, 1981.

[^3]: Pasquale, Frank. *The Black Box Society: The Secret Algorithms That
Control Money and Information, 2015.

[^3]: Pasquale, Frank. *The Black Box Society: The Secret Algorithms That Control
Money and Information.* Cambridge, Mass: Harvard University Press, 2015.

[^4]: Hayles, N. Katherine. “Cognition Everywhere: The Rise of the Cognitive
Nonconscious and the Costs of Consciousness.” *New Literary History New
Literary History* 45, no. 2 (2014): 199–220.

[^5]: See Wittgenstein, Ludwig, R. G Bosanquet, and Cora Diamond.
*Wittgenstein's Lectures on the Foundations of Mathematics, Cambridge, 1939:
From the Notes of R.G. Bosanquet, Norman Malcolm, Rush Rhees, and Yorick
Smythies*. Ithaca, N.Y.: Cornell University Press, 1976: 282 and Wittgenstein,
Ludwig, and Rush Rhees. *Philosophical grammar*. Berkeley: University of
California Press, 1974: 60-70.

[^6]: Edsger, Dijkstra. “The Fruits of Misunderstanding.” Netherlands, May 19,
1983.

[^7]: Winner, Langdon. *Autonomous Technology: Technics-out-of-Control as a
Theme in Political Thought*. Cambridge, Mass.: MIT Press, 1978: 279-305.

[^8]: cited in Winner, Langdon. *Autonomous Technology: Technics-out-of-Control as a
Theme in Political Thought*. Cambridge, Mass.: MIT Press, 1978: 305

[^9]: Horkheimer, Max. *Eclipse of Reason*. New York: Continuum, 1974.

[^10]: See for example Pitt, J., and A. Diaconescu. “Structure and Governance
of Communities for the Digital Society.” In 2015 IEEE International Conference
on Autonomic Computing (ICAC), 279–84, 2015.
